{
  "cveId": "CVE-2025-66448",
  "eventName": "New CVE Received",
  "cveChangeId": "4481EE65-C1AD-4244-A85D-BEC5E77A4A9A",
  "sourceIdentifier": "security-advisories@github.com",
  "created": "2025-12-01T23:15:54.213",
  "details": [
    {
      "action": "Added",
      "type": "Description",
      "newValue": "vLLM is an inference and serving engine for large language models (LLMs). Prior to 0.11.1, vllm has a critical remote code execution vector in a config class named Nemotron_Nano_VL_Config. When vllm loads a model config that contains an auto_map entry, the config class resolves that mapping with get_class_from_dynamic_module(...) and immediately instantiates the returned class. This fetches and executes Python from the remote repository referenced in the auto_map string. Crucially, this happens even when the caller explicitly sets trust_remote_code=False in vllm.transformers_utils.config.get_config. In practice, an attacker can publish a benign-looking frontend repo whose config.json points via auto_map to a separate malicious backend repo; loading the frontend will silently run the backendâ€™s code on the victim host. This vulnerability is fixed in 0.11.1."
    },
    {
      "action": "Added",
      "type": "CVSS V3.1",
      "newValue": "AV:N/AC:H/PR:L/UI:R/S:U/C:H/I:H/A:H"
    },
    {
      "action": "Added",
      "type": "CWE",
      "newValue": "CWE-94"
    },
    {
      "action": "Added",
      "type": "Reference",
      "newValue": "https://github.com/vllm-project/vllm/commit/ffb08379d8870a1a81ba82b72797f196838d0c86"
    },
    {
      "action": "Added",
      "type": "Reference",
      "newValue": "https://github.com/vllm-project/vllm/pull/28126"
    },
    {
      "action": "Added",
      "type": "Reference",
      "newValue": "https://github.com/vllm-project/vllm/security/advisories/GHSA-8fr4-5q9j-m8gm"
    }
  ]
}